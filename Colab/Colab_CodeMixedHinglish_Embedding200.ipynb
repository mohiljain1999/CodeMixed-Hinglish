{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodeMixedHinglish.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL6hHXB5WIqS",
        "colab_type": "code",
        "outputId": "332bf2ed-211d-46cc-9108-ab6fc8c2b1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git  clone https://github.com/vik235/CodeMixed-Hinglish "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CodeMixed-Hinglish'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 716 (delta 37), reused 125 (delta 23), pack-reused 573\n",
            "Receiving objects: 100% (716/716), 71.39 MiB | 25.34 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n",
            "Checking out files: 100% (691/691), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-uQ5LsvWeN6",
        "colab_type": "code",
        "outputId": "4acd9abe-9a5c-4dc3-f73d-b219ea8d84c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleansing.ipynb\t\t\t   Model_dev_Hot.py\n",
            "data\t\t\t\t   modelperf\n",
            "DataSplit.ipynb\t\t\t   models\n",
            "englishmodel.ipynb\t\t   New\\ Text\\ Document.txt\n",
            "FinalModels\t\t\t   Preprocessing.ipynb\n",
            "HinglishWordRepresentations.ipynb  Preprocessing.py\n",
            "hot.ipynb\t\t\t   README.md\n",
            "hot.py\t\t\t\t   src_data_massage.ipynb\n",
            "indic_nlp_examples.ipynb\t   src_preprocess_messages.ipynb\n",
            "logs\t\t\t\t   training.py\n",
            "Model_dev_Hot.ipynb\t\t   Transliteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvBEWQvwWq3G",
        "colab_type": "code",
        "outputId": "d24711e7-6777-4dfd-94c5-1cc2afefa78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "%cd CodeMixed-Hinglish/\n",
        "!dir"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'CodeMixed-Hinglish/'\n",
            "/content/CodeMixed-Hinglish\n",
            "Cleansing.ipynb\t\t\t   Model_dev_Hot.py\n",
            "data\t\t\t\t   modelperf\n",
            "DataSplit.ipynb\t\t\t   models\n",
            "englishmodel.ipynb\t\t   New\\ Text\\ Document.txt\n",
            "FinalModels\t\t\t   Preprocessing.ipynb\n",
            "HinglishWordRepresentations.ipynb  Preprocessing.py\n",
            "hot.ipynb\t\t\t   README.md\n",
            "hot.py\t\t\t\t   src_data_massage.ipynb\n",
            "indic_nlp_examples.ipynb\t   src_preprocess_messages.ipynb\n",
            "logs\t\t\t\t   training.py\n",
            "Model_dev_Hot.ipynb\t\t   Transliteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMIAnVjAXPR_",
        "colab_type": "code",
        "outputId": "230e3988-ba1f-49f9-a4f6-5cdb55e16aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install keras_metrics"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.4)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuu5hmoXJAx",
        "colab_type": "code",
        "outputId": "30e2331d-d096-40a7-b6cf-1eb9195306cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import io\n",
        "import csv\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences \n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dropout, SimpleRNN, LSTM, Bidirectional\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras_metrics\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "import keras.backend as K\n",
        "\n",
        "## Plotly\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOaPLhFDYTcs",
        "colab_type": "code",
        "outputId": "c62d8b9d-9466-4306-e788-70a3dbc1431e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-01 11:57:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-01 11:57:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-01 11:57:32--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.19MB/s    in 6m 29s  \n",
            "\n",
            "2019-12-01 12:04:01 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqdkM2GSYaOf",
        "colab_type": "code",
        "outputId": "f4794558-0682-4eb4-8bc5-8b48e6bca558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oph9I6vyYgZ9",
        "colab_type": "code",
        "outputId": "63266e5e-5a0f-4634-996e-81a2663c4b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Cleansing.ipynb\t\t     logs\n",
            " data\t\t\t\t     Model_dev_Hot.ipynb\n",
            " DataSplit.ipynb\t\t     Model_dev_Hot.py\n",
            " englishmodel.ipynb\t\t     modelperf\n",
            " FinalModels\t\t\t     models\n",
            " glove.6B.100d.txt\t\t    'New Text Document.txt'\n",
            " glove.6B.200d.txt\t\t     Preprocessing.ipynb\n",
            " glove.6B.300d.txt\t\t     Preprocessing.py\n",
            " glove.6B.50d.txt\t\t     README.md\n",
            " glove.6B.zip\t\t\t     src_data_massage.ipynb\n",
            " HinglishWordRepresentations.ipynb   src_preprocess_messages.ipynb\n",
            " hot.ipynb\t\t\t     training.py\n",
            " hot.py\t\t\t\t     Transliteration\n",
            " indic_nlp_examples.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BIjMpcjW8wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Set params for the model\n",
        "tensorBoard_logs_dir = 'logs'\n",
        "model_dir = 'models'\n",
        "glove_dir = '.\\\\models\\\\glove'\n",
        "train_dir = \"data/train/\"\n",
        "train_data = 'messages_3.csv'\n",
        "label_data = 'labels_3.csv'\n",
        "\n",
        "maxlen = 200\n",
        "training_samples = 2800\n",
        "validation_samples = 500# len(labels) - training_samples #\n",
        "max_words = 10000\n",
        "num_filters = 64 \n",
        "embedding_dim = 200\n",
        "num_filters = 64 \n",
        "num_classes = 3\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToqtEqkXXB3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "labels = []\n",
        "train_dir = \"data/train/\"\n",
        "\n",
        "with open(os.path.join(train_dir, train_data), newline ='') as messageData:\n",
        "    reader = csv.reader(messageData)\n",
        "    for row in reader:\n",
        "        message = (''.join(row))\n",
        "        texts.append(message)\n",
        "\n",
        "with open(os.path.join(train_dir, label_data)) as labelData:\n",
        "    reader = csv.reader(labelData)\n",
        "    for row in reader:\n",
        "        #label = (''.join(row))\n",
        "        labels.append(row)\n",
        "\n",
        "labels = np.squeeze(labels)#[(np.squeeze(i)) for i in labels]\n",
        "#np.squeeze(labels[:])\n",
        "#la\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8pieSmXa7_",
        "colab_type": "code",
        "outputId": "36147203-3a26-4124-9fd7-134672f40e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "encoded_Y = encoder.transform(labels,)\n",
        "labells = np_utils.to_categorical(encoded_Y)\n",
        "print(labells[0,])\n",
        "\n",
        "'''\n",
        "labells = np_utils.to_categorical(labels, num_classes=num_classes)\n",
        "labells[0:20,]\n",
        "np.sum(labells, axis = 0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1121., 1818., 1765.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7Cj4SXqYD0N",
        "colab_type": "code",
        "outputId": "c5614cd8-6799-4419-a162-0ac9cc387dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "##Tokenizer, Sequencer and padding via Keras\n",
        "np.random.seed(1) \n",
        "\n",
        "#tokenize the data for the maxwords\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "#Generate the sequences on texts on the the data by tokenizer\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.'% len(word_index))\n",
        "#print(word_index)\n",
        "#Padding sequences (making them all equal)\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of the data tensor:' , data.shape)\n",
        "print('Shape of the label tensor:' , labells.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "data = data[indices]\n",
        "labels = labells[indices,:]\n",
        "\n",
        "x_train = data#[:training_samples]\n",
        "y_train = labels#[:training_samples]\n",
        "print(indices[0:10])\n",
        "#x_test = data[training_samples:training_samples + validation_samples]\n",
        "#y_test = labels[training_samples:training_samples + validation_samples]\n",
        "\n",
        "print(\"Train length\" , len(x_train))\n",
        "#print(\"Test length\" , len(x_test))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7281 unique tokens.\n",
            "Shape of the data tensor: (4704, 200)\n",
            "Shape of the label tensor: (4704, 3)\n",
            "[3727 3729 4021 2968 4496 4258 2637 1766 3494 2416]\n",
            "Train length 4704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWhyGWZ5aITG",
        "colab_type": "code",
        "outputId": "22fc6be9-9b0d-4628-ceb9-5dc7217d1d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1) \n",
        "embedding_index = {}\n",
        "f = open(os.path.join('glove.6B.200d.txt'), encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "   # print(word)\n",
        "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
        "    embedding_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "\n",
        "print('Found %s word vectors' % len(embedding_index))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VQMSzFqaQ52",
        "colab_type": "code",
        "outputId": "ef453cc0-6550-46bc-99d7-1810f044a492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1) \n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "count = 0 \n",
        "ignored_words = []\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            ignored_words.append(word)  \n",
        "            count = count + 1\n",
        "print(embedding_matrix.shape)       \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2-VWkSBaTbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model_qualifier, model, location):\n",
        "    model_name = model_qualifier + \"-{}\".format(datetime.date.today()) + \"-{}\".format(time.time())\n",
        "    try:\n",
        "        model.save(os.path.join(location, model_name))\n",
        "        #plot_model(model, to_file=os.path.join(location, model_name)+ '.png')\n",
        "    except:\n",
        "        print(\"Exception occured while saving the model to disc.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PC9UkC1jEeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cd66f950-e4f8-415c-b09c-7202dcee50e7"
      },
      "source": [
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmS3E-wSaVk3",
        "colab_type": "code",
        "outputId": "ec168ced-5172-4828-b63a-bfd3e2c3749f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "np.random.seed(1) \n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "'''\n",
        "model.add(LSTM(32, recurrent_dropout = 0.2, return_sequences=True))\n",
        "model.add(LSTM(32, recurrent_dropout = 0.2, return_sequences=True))\n",
        "model.add(LSTM(32, recurrent_dropout = 0.2, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "'''\n",
        "model.add(Bidirectional(LSTM(32, recurrent_dropout = 0.4, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32, recurrent_dropout = 0.4, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32, recurrent_dropout = 0.4, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = True\n",
        "model_name = \"CodeMixed-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2-{}\".format(int(time.time()))\n",
        "model.summary()\n",
        "\n",
        "'''\n",
        "model = load_model('.\\\\models\\Best_English-Emb-TFL-CNN_64x7x3_DO-Dense_64x2_model.h5')\n",
        "model_name = \"CodeMixed-Emb-UnTrained-CNN_64x7x3_DO-Dense_64x1-{}\".format(int(time.time()))\n",
        "\n",
        "model.trainable = True\n",
        "set_trainable = False\n",
        "for layer in model.layers:\n",
        "   # print(layer.name, ': ', layer.trainable)\n",
        "    if layer.name in ['dense_27','dense_28', 'dense_29']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "for layer in model.layers:        \n",
        "    print(layer.name, ': ', layer.trainable)\n",
        "\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])   \n",
        "\n",
        "'''\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 200)          2000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200, 64)           59648     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200, 64)           24832     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 200, 64)           24832     \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 2,143,171\n",
            "Trainable params: 2,142,915\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = load_model(\\'.\\\\models\\\\Best_English-Emb-TFL-CNN_64x7x3_DO-Dense_64x2_model.h5\\')\\nmodel_name = \"CodeMixed-Emb-UnTrained-CNN_64x7x3_DO-Dense_64x1-{}\".format(int(time.time()))\\n\\nmodel.trainable = True\\nset_trainable = False\\nfor layer in model.layers:\\n   # print(layer.name, \\': \\', layer.trainable)\\n    if layer.name in [\\'dense_27\\',\\'dense_28\\', \\'dense_29\\']:\\n        set_trainable = True\\n    if set_trainable:\\n        layer.trainable = True\\n    else:\\n        layer.trainable = False\\n\\nmodel.layers[0].set_weights([embedding_matrix])\\nmodel.layers[0].trainable = False\\n\\nfor layer in model.layers:        \\n    print(layer.name, \\': \\', layer.trainable)\\n\\nlayers = [(layer, layer.name, layer.trainable) for layer in model.layers]\\npd.DataFrame(layers, columns=[\\'Layer Type\\', \\'Layer Name\\', \\'Layer Trainable\\'])   \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x4b2rPoaaGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b7d8977c-d4ec-46ed-e9d8-89a6e733012d"
      },
      "source": [
        "optimizer = Adam(lr=0.005, decay=1e-6)\n",
        "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics=['acc'])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzVXfy0GahJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callbacks \n",
        "earlystopping = EarlyStopping(monitor='val_acc', mode='min', verbose=1, patience=100, restore_best_weights= True)\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint('models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5', monitor='val_acc', mode='min', verbose=1)\n",
        "\n",
        "reduce_lr_plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "tensorboard = TensorBoard(log_dir = tensorBoard_logs_dir + '{}'.format(model_name), \n",
        "                         histogram_freq=1,\n",
        "                         #embeddings_freq=1\n",
        "                         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL8-fFJUazxG",
        "colab_type": "code",
        "outputId": "674465f8-0e83-425e-b2aa-8e9aef6d499b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 500, batch_size = 1024,validation_split=0.1, callbacks = [tensorboard, earlystopping, reduce_lr_plateau, modelcheckpoint])\n",
        "#results = model.evaluate(x_test, y_test)\n",
        "#model.save_weights(model_dir + '{}'.format(model_name)+'.h5')\n",
        "save_model(\"Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model\", model, \"models\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4233 samples, validate on 471 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1068: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/500\n",
            "4233/4233 [==============================] - 25s 6ms/step - loss: 1.3617 - acc: 0.4193 - val_loss: 1.6554 - val_acc: 0.4883\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "\n",
            "Epoch 00001: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 2/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.8777 - acc: 0.6312 - val_loss: 1.1610 - val_acc: 0.6921\n",
            "\n",
            "Epoch 00002: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 3/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.6660 - acc: 0.7307 - val_loss: 0.7768 - val_acc: 0.7792\n",
            "\n",
            "Epoch 00003: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 4/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.5244 - acc: 0.7964 - val_loss: 0.7398 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00004: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 5/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.4052 - acc: 0.8611 - val_loss: 0.6741 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00005: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 6/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.3145 - acc: 0.9036 - val_loss: 0.6941 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00006: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 7/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.2380 - acc: 0.9322 - val_loss: 0.6185 - val_acc: 0.8705\n",
            "\n",
            "Epoch 00007: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 8/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.1785 - acc: 0.9511 - val_loss: 0.5914 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00008: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 9/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.1266 - acc: 0.9709 - val_loss: 0.6244 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00009: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 10/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0954 - acc: 0.9818 - val_loss: 0.7194 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00010: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 11/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0673 - acc: 0.9880 - val_loss: 0.6267 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00011: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 12/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0528 - acc: 0.9896 - val_loss: 0.7099 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00012: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 13/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0517 - acc: 0.9908 - val_loss: 0.6877 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00013: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 14/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0485 - acc: 0.9924 - val_loss: 0.7015 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00014: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 15/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0439 - acc: 0.9931 - val_loss: 0.6426 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00015: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 16/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0411 - acc: 0.9939 - val_loss: 0.7114 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00016: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 17/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0418 - acc: 0.9936 - val_loss: 0.7413 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00017: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 18/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0340 - acc: 0.9943 - val_loss: 0.6946 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00018: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 19/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0320 - acc: 0.9941 - val_loss: 0.6647 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00019: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 20/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0307 - acc: 0.9943 - val_loss: 0.6500 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00020: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 21/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0300 - acc: 0.9953 - val_loss: 0.6118 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00021: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 22/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0287 - acc: 0.9967 - val_loss: 0.6246 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00022: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 23/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0283 - acc: 0.9965 - val_loss: 0.6305 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00023: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 24/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0265 - acc: 0.9965 - val_loss: 0.6772 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00024: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 25/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0205 - acc: 0.9972 - val_loss: 0.7094 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00025: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 26/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0224 - acc: 0.9972 - val_loss: 0.6971 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00026: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 27/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0234 - acc: 0.9969 - val_loss: 0.6820 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00027: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 28/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0206 - acc: 0.9972 - val_loss: 0.6645 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00028: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 29/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0213 - acc: 0.9972 - val_loss: 0.6535 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00029: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 30/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0204 - acc: 0.9969 - val_loss: 0.6421 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00030: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 31/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0202 - acc: 0.9965 - val_loss: 0.6351 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00031: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 32/500\n",
            "4233/4233 [==============================] - 19s 4ms/step - loss: 0.0200 - acc: 0.9969 - val_loss: 0.6295 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00032: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 33/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0204 - acc: 0.9972 - val_loss: 0.6309 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00033: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 34/500\n",
            "4233/4233 [==============================] - 19s 4ms/step - loss: 0.0172 - acc: 0.9967 - val_loss: 0.6345 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00034: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 35/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0175 - acc: 0.9969 - val_loss: 0.6328 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00035: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 36/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0194 - acc: 0.9972 - val_loss: 0.6283 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00036: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 37/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0183 - acc: 0.9969 - val_loss: 0.6250 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00037: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 38/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0182 - acc: 0.9972 - val_loss: 0.6221 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00038: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 39/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0200 - acc: 0.9960 - val_loss: 0.6199 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00039: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 40/500\n",
            "4233/4233 [==============================] - 19s 4ms/step - loss: 0.0160 - acc: 0.9972 - val_loss: 0.6181 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00040: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 41/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0180 - acc: 0.9976 - val_loss: 0.6161 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00041: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 42/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0154 - acc: 0.9972 - val_loss: 0.6142 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00042: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 43/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0144 - acc: 0.9976 - val_loss: 0.6121 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00043: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 44/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0158 - acc: 0.9976 - val_loss: 0.6103 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00044: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 45/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0169 - acc: 0.9972 - val_loss: 0.6078 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00045: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 46/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0166 - acc: 0.9976 - val_loss: 0.6058 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00046: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 47/500\n",
            "4233/4233 [==============================] - 18s 4ms/step - loss: 0.0175 - acc: 0.9976 - val_loss: 0.6038 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00047: saving model to models/Colab_Best_Hinglish-Emb-BiLSTM_32x2_64x1_DO-Dense_64x2_model.h5\n",
            "Epoch 48/500\n",
            "3072/4233 [====================>.........] - ETA: 3s - loss: 0.0198 - acc: 0.9967"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_nLTew9bERE",
        "colab_type": "code",
        "outputId": "98b072c6-8abd-4666-cb2e-64ea57dc0b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleansing.ipynb\t\t\t   logs\n",
            "data\t\t\t\t   Model_dev_Hot.ipynb\n",
            "DataSplit.ipynb\t\t\t   Model_dev_Hot.py\n",
            "englishmodel.ipynb\t\t   modelperf\n",
            "FinalModels\t\t\t   models\n",
            "glove.6B.100d.txt\t\t   New\\ Text\\ Document.txt\n",
            "glove.6B.200d.txt\t\t   Preprocessing.ipynb\n",
            "glove.6B.300d.txt\t\t   Preprocessing.py\n",
            "glove.6B.50d.txt\t\t   README.md\n",
            "glove.6B.zip\t\t\t   src_data_massage.ipynb\n",
            "HinglishWordRepresentations.ipynb  src_preprocess_messages.ipynb\n",
            "hot.ipynb\t\t\t   training.py\n",
            "hot.py\t\t\t\t   Transliteration\n",
            "indic_nlp_examples.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVtZPz3Mhzks",
        "colab_type": "code",
        "outputId": "6978a4ae-8d81-4773-eb6a-29a087a6a40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label ='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label ='Validation acc')\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label ='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label ='Validation Loss')\n",
        "plt.title(\"Training and validation Losses\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzkNFvJJDbd4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo6RHiKtpUGc",
        "colab_type": "code",
        "outputId": "7b07b909-60bb-404a-d013-1d790cba1420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-30 14:09:57--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.229.196.117, 52.71.210.177, 52.3.157.51, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.229.196.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  18.1MB/s    in 0.7s    \n",
            "\n",
            "2019-11-30 14:09:58 (18.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlxsJ9IPp_Sy",
        "colab_type": "code",
        "outputId": "56e498b6-c0ec-43c3-de48-2c79ec13c76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd logs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CodeMixed-Hinglish/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ7tkLR4qK-y",
        "colab_type": "code",
        "outputId": "7f4a30f4-7a4c-4227-c9c3-0ddb3ee4a526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CodeMixed-HOT-Emb-TFF-CONV-64x1x3-MP-Dense-64x1-BN-DO-1573388387\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x2x3-MP-Dense-64x1-BN-DO-1573388542\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x2x7-MP-Dense-64x1-BN-DO-1573388670\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x3x7-MP-Dense-64x1-BN-DO-1573388824\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x3x7-MP-Dense-64x1-BN-DO-1574001521\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x3x7-MP-Dense-64x2-BN-DO-1573389431\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x3x7-MP-Dense-64x2-BN-DO-1573997675\n",
            "CodeMixed-HOT-Emb-TFF-CONV-64x3x7-MP-Dense-64x2-BN-DO-1574001926\n",
            "CodeMixed-HOT-Emb-TFF-CONV-TransCNN-Model-1573389142\n",
            "CodeMixed-HOT-Emb-TFF-Fl-Dense-64x1-BN-DO-1573388013\n",
            "CodeMixed-HOT-Emb-TFT-CONV-64x3x7-MP-Dense-64x1-BN-DO-1574001702\n",
            "CodeMixed-HOT-Emb-TFT-CONV-64x3x7-MP-Dense-64x2-BN-DO-1574001858\n",
            "CodeMixed-HOT-Emb-TFT-Fl-Dense-64x1-BN-DO-1573388101\n",
            "CodeMixed-HOT-TRANSCNN-BASE-1573389345\n",
            "metadata.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}